{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-09T09:32:41.951273Z",
     "start_time": "2025-03-09T09:32:40.936042Z"
    }
   },
   "source": "!pip install ArabertPreprocessor",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: Could not find a version that satisfies the requirement ArabertPreprocessor (from versions: none)\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\u001B[31mERROR: No matching distribution found for ArabertPreprocessor\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-09T09:32:51.574873Z",
     "start_time": "2025-03-09T09:32:45.694780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# finetune process \n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ],
   "id": "c9e43e1f16d0e37f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:33:10.517665Z",
     "start_time": "2025-03-09T09:33:08.089665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load the data\n",
    "bbc_data = pd.read_csv('bbc_news_arabic_summarization.csv')\n",
    "# Randomly sample 50% of the dataset\n",
    "#bbc_data = bbc_data.sample(frac=0.5, random_state=42)"
   ],
   "id": "57dce74dad96fd3d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:34:34.795886Z",
     "start_time": "2025-03-09T09:34:34.788534Z"
    }
   },
   "cell_type": "code",
   "source": "bbc_data.head()",
   "id": "3560b6266e9792eb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                        id  \\\n",
       "0  140323_russian_troops_crimea_naval_base   \n",
       "1                    130528_egypt_nile_dam   \n",
       "2                           world-47242349   \n",
       "3                        vert-cul-55078328   \n",
       "4                     141023_yemen_hodeida   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.bbc.com/arabic/worldnews/2014/03/1...   \n",
       "1  https://www.bbc.com/arabic/middleeast/2013/05/...   \n",
       "2          https://www.bbc.com/arabic/world-47242349   \n",
       "3       https://www.bbc.com/arabic/vert-cul-55078328   \n",
       "4  https://www.bbc.com/arabic/middleeast/2014/10/...   \n",
       "\n",
       "                                               title  \\\n",
       "0           Ø§Ù„Ù‚ÙˆØ§Øª Ø§Ù„Ø£ÙˆÙƒØ±Ø§Ù†ÙŠØ© ØªØ¨Ø¯Ø£ Ø§Ù„Ø§Ù†Ø³Ø­Ø§Ø¨ Ù…Ù† Ø§Ù„Ù‚Ø±Ù…   \n",
       "1    Ù‡Ù„ ÙŠÙØ±Ø¶ Ø³Ø¯ Ø§Ù„Ù†Ù‡Ø¶Ø© Ø§Ù„Ø¥Ø«ÙŠÙˆØ¨ÙŠ ÙˆØ§Ù‚Ø¹Ø§ Ø¬Ø¯ÙŠØ¯Ø§ Ø¹Ù„Ù‰ Ù…ØµØ±ØŸ   \n",
       "2  ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù…Ù†Ø·Ù‚Ø© ÙƒØ´Ù…ÙŠØ± Ø§Ù„ØªÙŠ ØªØ³Ø¨Ø¨Øª Ø¨Ø­Ø±Ø¨ÙŠÙ† Ø¨ÙŠÙ† Ø§Ù„Ù‡...   \n",
       "3  Ù…Ø§Ø°Ø§ ØªØ¹Ø±Ù Ø¹Ù† Ø§Ù„Ø¹Ø§Ù„Ù… Ø§Ù„Ø®ÙÙŠ Ù„Ù„Ù…Ø¹Ø§Ø¨Ø¯ Ø§Ù„ÙŠØ§Ø¨Ø§Ù†ÙŠØ© Ø§Ù„...   \n",
       "4  Ø§Ø´ØªØ¨Ø§Ùƒ Ø¨ÙŠÙ† Ø§Ù„Ø­ÙˆØ«ÙŠÙŠÙ† Ùˆ\"Ø§Ù„Ø­Ø±Ø§Ùƒ Ø§Ù„ØªÙ‡Ø§Ù…ÙŠ\" ÙÙŠ Ø§Ù„Ø­Ø¯ÙŠ...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Ø¨Ø¯Ø£Øª Ø§Ù„Ù‚ÙˆØ§Øª Ø§Ù„Ø£ÙˆÙƒØ±Ø§Ù†ÙŠØ© Ø§Ù„Ø§Ù†Ø³Ø­Ø§Ø¨ Ù…Ù† Ø´Ø¨Ù‡ Ø¬Ø²ÙŠØ±Ø© Ø§...   \n",
       "1  \"Ù‡Ù„ Ø³ÙŠØªÙ… ØªØºÙŠÙŠØ± Ø§Ù„Ø¹Ø¨Ø§Ø±Ø© Ø§Ù„Ø´Ù‡ÙŠØ±Ø© Ù„Ù„Ù…Ø¤Ø±Ø® Ø§Ù„ÙŠÙˆÙ†Ø§Ù†ÙŠ...   \n",
       "2  Ù‚Ø§Ù„Øª Ø§Ù„Ø´Ø±Ø·Ø© ÙÙŠ Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ù‡Ù†Ø¯ÙŠ Ù…Ù† Ø¥Ù‚Ù„ÙŠÙ… ÙƒØ´Ù…ÙŠØ± Ø¥Ù†...   \n",
       "3  ÙÙŠ Ø¹Ø§Ù… 816ØŒ ØªØ¬ÙˆÙ„ Ø±Ø§Ù‡Ø¨ ÙŠØ¯Ø¹Ù‰ ÙƒÙˆÙƒØ§ÙŠØŒ ÙÙŠ Ø§Ù„Ù…Ù†Ø­Ø¯Ø±Ø§Øª...   \n",
       "4  Ø£ÙƒØ¯ Ù…ØµØ¯Ø± ÙÙŠ \"Ø§Ù„Ø­Ø±Ø§Ùƒ Ø§Ù„ØªÙ‡Ø§Ù…ÙŠ\" Ù„Ø£Ø¨Ù†Ø§Ø¡ Ù…Ø­Ø§ÙØ¸Ø© Ø§Ù„Ø­...   \n",
       "\n",
       "                                                text  \n",
       "0  ÙˆÙƒØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ Ø§Ù„Ø£ÙˆÙƒØ±Ø§Ù†ÙŠ Ø§Ù„Ù…Ø¤Ù‚ØªØŒ Ø§Ù„ÙƒØ³Ù†Ø¯Ø± ØªÙˆØ±ØªØ´ÙŠÙ†Ùˆ...  \n",
       "1  Ø¨Ø­Ù„ÙˆÙ„ Ø¹Ø§Ù… 2050 Ø³ØªØ­ØªØ§Ø¬ Ù…ØµØ± Ø¥Ù„Ù‰ 21 Ù…Ù„ÙŠØ§Ø± Ù…ØªØ± Ù…ÙƒØ¹...  \n",
       "2  ÙˆØ°ÙƒØ±Øª ÙˆÙƒØ§Ù„Ø© Ø§Ù„Ø£Ù†Ø¨Ø§Ø¡ Ø§Ù„Ù…Ø­Ù„ÙŠØ© (Ø¬ÙŠ.Ø¥Ù†.Ø¥Ø³) Ø£Ù† Ø¬Ù…Ø§Ø¹...  \n",
       "3  ÙˆÙˆÙ‚Ø¹ Ø§Ø®ØªÙŠØ§Ø±Ù‡ Ø¹Ù„Ù‰ ÙˆØ§Ø¯ Ø¹Ù…Ù‚Ù‡ 800 Ù…ØªØ± Ù…Ø­Ø§Ø· Ø¨Ø«Ù…Ø§Ù†ÙŠ ...  \n",
       "4  Ù…Ø³Ù„Ø­ Ø­ÙˆØ«ÙŠ ÙÙŠ Ø¥Ø¨ ÙˆÙ‚Ø§Ù„ Ø§Ù„Ù…ØµØ¯Ø± Ø¥Ù† Ø§Ù„Ù…Ø³Ù„Ø­ÙŠÙ† Ø§Ù„Ø­ÙˆØ«ÙŠ...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140323_russian_troops_crimea_naval_base</td>\n",
       "      <td>https://www.bbc.com/arabic/worldnews/2014/03/1...</td>\n",
       "      <td>Ø§Ù„Ù‚ÙˆØ§Øª Ø§Ù„Ø£ÙˆÙƒØ±Ø§Ù†ÙŠØ© ØªØ¨Ø¯Ø£ Ø§Ù„Ø§Ù†Ø³Ø­Ø§Ø¨ Ù…Ù† Ø§Ù„Ù‚Ø±Ù…</td>\n",
       "      <td>Ø¨Ø¯Ø£Øª Ø§Ù„Ù‚ÙˆØ§Øª Ø§Ù„Ø£ÙˆÙƒØ±Ø§Ù†ÙŠØ© Ø§Ù„Ø§Ù†Ø³Ø­Ø§Ø¨ Ù…Ù† Ø´Ø¨Ù‡ Ø¬Ø²ÙŠØ±Ø© Ø§...</td>\n",
       "      <td>ÙˆÙƒØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ Ø§Ù„Ø£ÙˆÙƒØ±Ø§Ù†ÙŠ Ø§Ù„Ù…Ø¤Ù‚ØªØŒ Ø§Ù„ÙƒØ³Ù†Ø¯Ø± ØªÙˆØ±ØªØ´ÙŠÙ†Ùˆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130528_egypt_nile_dam</td>\n",
       "      <td>https://www.bbc.com/arabic/middleeast/2013/05/...</td>\n",
       "      <td>Ù‡Ù„ ÙŠÙØ±Ø¶ Ø³Ø¯ Ø§Ù„Ù†Ù‡Ø¶Ø© Ø§Ù„Ø¥Ø«ÙŠÙˆØ¨ÙŠ ÙˆØ§Ù‚Ø¹Ø§ Ø¬Ø¯ÙŠØ¯Ø§ Ø¹Ù„Ù‰ Ù…ØµØ±ØŸ</td>\n",
       "      <td>\"Ù‡Ù„ Ø³ÙŠØªÙ… ØªØºÙŠÙŠØ± Ø§Ù„Ø¹Ø¨Ø§Ø±Ø© Ø§Ù„Ø´Ù‡ÙŠØ±Ø© Ù„Ù„Ù…Ø¤Ø±Ø® Ø§Ù„ÙŠÙˆÙ†Ø§Ù†ÙŠ...</td>\n",
       "      <td>Ø¨Ø­Ù„ÙˆÙ„ Ø¹Ø§Ù… 2050 Ø³ØªØ­ØªØ§Ø¬ Ù…ØµØ± Ø¥Ù„Ù‰ 21 Ù…Ù„ÙŠØ§Ø± Ù…ØªØ± Ù…ÙƒØ¹...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>world-47242349</td>\n",
       "      <td>https://www.bbc.com/arabic/world-47242349</td>\n",
       "      <td>ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù…Ù†Ø·Ù‚Ø© ÙƒØ´Ù…ÙŠØ± Ø§Ù„ØªÙŠ ØªØ³Ø¨Ø¨Øª Ø¨Ø­Ø±Ø¨ÙŠÙ† Ø¨ÙŠÙ† Ø§Ù„Ù‡...</td>\n",
       "      <td>Ù‚Ø§Ù„Øª Ø§Ù„Ø´Ø±Ø·Ø© ÙÙŠ Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ù‡Ù†Ø¯ÙŠ Ù…Ù† Ø¥Ù‚Ù„ÙŠÙ… ÙƒØ´Ù…ÙŠØ± Ø¥Ù†...</td>\n",
       "      <td>ÙˆØ°ÙƒØ±Øª ÙˆÙƒØ§Ù„Ø© Ø§Ù„Ø£Ù†Ø¨Ø§Ø¡ Ø§Ù„Ù…Ø­Ù„ÙŠØ© (Ø¬ÙŠ.Ø¥Ù†.Ø¥Ø³) Ø£Ù† Ø¬Ù…Ø§Ø¹...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vert-cul-55078328</td>\n",
       "      <td>https://www.bbc.com/arabic/vert-cul-55078328</td>\n",
       "      <td>Ù…Ø§Ø°Ø§ ØªØ¹Ø±Ù Ø¹Ù† Ø§Ù„Ø¹Ø§Ù„Ù… Ø§Ù„Ø®ÙÙŠ Ù„Ù„Ù…Ø¹Ø§Ø¨Ø¯ Ø§Ù„ÙŠØ§Ø¨Ø§Ù†ÙŠØ© Ø§Ù„...</td>\n",
       "      <td>ÙÙŠ Ø¹Ø§Ù… 816ØŒ ØªØ¬ÙˆÙ„ Ø±Ø§Ù‡Ø¨ ÙŠØ¯Ø¹Ù‰ ÙƒÙˆÙƒØ§ÙŠØŒ ÙÙŠ Ø§Ù„Ù…Ù†Ø­Ø¯Ø±Ø§Øª...</td>\n",
       "      <td>ÙˆÙˆÙ‚Ø¹ Ø§Ø®ØªÙŠØ§Ø±Ù‡ Ø¹Ù„Ù‰ ÙˆØ§Ø¯ Ø¹Ù…Ù‚Ù‡ 800 Ù…ØªØ± Ù…Ø­Ø§Ø· Ø¨Ø«Ù…Ø§Ù†ÙŠ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141023_yemen_hodeida</td>\n",
       "      <td>https://www.bbc.com/arabic/middleeast/2014/10/...</td>\n",
       "      <td>Ø§Ø´ØªØ¨Ø§Ùƒ Ø¨ÙŠÙ† Ø§Ù„Ø­ÙˆØ«ÙŠÙŠÙ† Ùˆ\"Ø§Ù„Ø­Ø±Ø§Ùƒ Ø§Ù„ØªÙ‡Ø§Ù…ÙŠ\" ÙÙŠ Ø§Ù„Ø­Ø¯ÙŠ...</td>\n",
       "      <td>Ø£ÙƒØ¯ Ù…ØµØ¯Ø± ÙÙŠ \"Ø§Ù„Ø­Ø±Ø§Ùƒ Ø§Ù„ØªÙ‡Ø§Ù…ÙŠ\" Ù„Ø£Ø¨Ù†Ø§Ø¡ Ù…Ø­Ø§ÙØ¸Ø© Ø§Ù„Ø­...</td>\n",
       "      <td>Ù…Ø³Ù„Ø­ Ø­ÙˆØ«ÙŠ ÙÙŠ Ø¥Ø¨ ÙˆÙ‚Ø§Ù„ Ø§Ù„Ù…ØµØ¯Ø± Ø¥Ù† Ø§Ù„Ù…Ø³Ù„Ø­ÙŠÙ† Ø§Ù„Ø­ÙˆØ«ÙŠ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:34:38.416360Z",
     "start_time": "2025-03-09T09:34:38.357791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bbc_data.dropna(subset=['text', 'summary'], inplace=True)\n",
    "bbc_data = bbc_data.drop(columns=['id','url','title','summary'])"
   ],
   "id": "c2cec1daa08eea41",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:35:04.584433Z",
     "start_time": "2025-03-09T09:35:03.065628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "bbc_dataset= Dataset.from_pandas(bbc_data)\n",
    "train_test_split = bbc_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "bbc_train_dataset1 = train_test_split['train']\n",
    "bbc_test_dataset = train_test_split['test']\n",
    "# Split the training set further into 80% train and 20% validation\n",
    "bbc_train_dataset, bbc_val_dataset = bbc_train_dataset1.train_test_split(test_size=0.2, seed=42).values()\n",
    "\n"
   ],
   "id": "533a49cbf4a5dda9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jameelamer/MasterProject/Summarization/summrization_webapp/flaskProject2/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:42:31.817058Z",
     "start_time": "2025-03-09T09:41:35.261519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "\n",
    "# Initialize AraBERT preprocessor\n",
    "arabert_prep = ArabertPreprocessor(\"aubmindlab/aragpt2-base\")\n",
    "# Preprocess dataset for Arabic\n",
    "def preprocess_arabic(examples):\n",
    "    examples[\"text\"] = [arabert_prep.preprocess(text) for text in examples[\"text\"]]\n",
    "    return examples\n",
    "\n",
    "\n",
    "train_dataset = bbc_train_dataset.map(preprocess_arabic, batched=True)\n",
    "val_dataset = bbc_val_dataset.map(preprocess_arabic, batched=True)\n",
    "test_dataset = bbc_test_dataset.map(preprocess_arabic, batched=True)\n",
    "# Load GPT-2 model and tokenizer for Arabic\n",
    "model_name = \"aubmindlab/aragpt2-base\"  # Pre-trained Arabic GPT-2\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "aa083fef65f6d9fd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30013/30013 [00:35<00:00, 839.65 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7504/7504 [00:08<00:00, 863.98 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9380/9380 [00:10<00:00, 861.21 examples/s]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:45:06.953938Z",
     "start_time": "2025-03-09T09:45:06.948747Z"
    }
   },
   "cell_type": "code",
   "source": "print(train_dataset.column_names)",
   "id": "79bb2924ccead2ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text']\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:47:07.501967Z",
     "start_time": "2025-03-09T09:45:49.961270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tokenize dataset\n",
    "# Set the pad token to <|endoftext|>\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "#tokenized_datasets = train_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])   \"__index_level_0__\"\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "# Data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False  # Causal language modeling\n",
    ")\n",
    "print(train_dataset.column_names)\n"
   ],
   "id": "10cafcf778d1da15",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30013/30013 [00:59<00:00, 506.49 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7504/7504 [00:17<00:00, 439.25 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_ids', 'attention_mask']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "426ea66247c216ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:52:39.781499Z",
     "start_time": "2025-03-09T09:52:39.683235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./SSS_arabic_gpt2_finetuned\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=4,  # Adjust for CPU\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=500,\n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"epoch\",\n",
    "    use_cpu=True,\n",
    "    remove_unused_columns=False,  # Prevent Trainer from filtering columns\n",
    ")\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n"
   ],
   "id": "cdacc378c995ab83",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[20]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Training arguments\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m training_args = \u001B[43mTrainingArguments\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m./SSS_arabic_gpt2_finetuned\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[43meval_strategy\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mepoch\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m5e-5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[43mper_device_train_batch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Adjust for CPU\u001B[39;49;00m\n\u001B[32m      7\u001B[39m \u001B[43m    \u001B[49m\u001B[43mper_device_eval_batch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m4\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_train_epochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m3\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m    \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.01\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlogging_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m./logs\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlogging_steps\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m500\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[43m    \u001B[49m\u001B[43msave_total_limit\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     13\u001B[39m \u001B[43m    \u001B[49m\u001B[43msave_strategy\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mepoch\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_cpu\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     15\u001B[39m \u001B[43m    \u001B[49m\u001B[43mremove_unused_columns\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Prevent Trainer from filtering columns\u001B[39;49;00m\n\u001B[32m     16\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     18\u001B[39m \u001B[38;5;66;03m# Trainer setup\u001B[39;00m\n\u001B[32m     19\u001B[39m trainer = Trainer(\n\u001B[32m     20\u001B[39m     model=model,\n\u001B[32m     21\u001B[39m     args=training_args,\n\u001B[32m   (...)\u001B[39m\u001B[32m     25\u001B[39m     data_collator=data_collator,\n\u001B[32m     26\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<string>:131\u001B[39m, in \u001B[36m__init__\u001B[39m\u001B[34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, eval_do_concat_batches, fp16_backend, evaluation_strategy, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics, eval_on_start, eval_use_gather_object)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/MasterProject/Summarization/summrization_webapp/flaskProject2/.venv/lib/python3.12/site-packages/transformers/training_args.py:1730\u001B[39m, in \u001B[36m__post_init__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m      0\u001B[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/MasterProject/Summarization/summrization_webapp/flaskProject2/.venv/lib/python3.12/site-packages/transformers/training_args.py:2227\u001B[39m, in \u001B[36mdevice\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   2225\u001B[39m     torch.cuda.set_device(device)\n\u001B[32m   2226\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m is_sagemaker_dp_enabled():\n\u001B[32m-> \u001B[39m\u001B[32m2227\u001B[39m     accelerator_state_kwargs[\u001B[33m\"\u001B[39m\u001B[33m_use_sagemaker_dp\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m   2228\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.deepspeed:\n\u001B[32m   2229\u001B[39m     accelerator_state_kwargs[\u001B[33m\"\u001B[39m\u001B[33muse_deepspeed\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/MasterProject/Summarization/summrization_webapp/flaskProject2/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:60\u001B[39m, in \u001B[36m__get__\u001B[39m\u001B[34m(self, obj, objtype)\u001B[39m\n\u001B[32m     58\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33munreadable attribute\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     59\u001B[39m attr = \u001B[33m\"\u001B[39m\u001B[33m__cached_\u001B[39m\u001B[33m\"\u001B[39m + \u001B[38;5;28mself\u001B[39m.fget.\u001B[34m__name__\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m60\u001B[39m cached = \u001B[38;5;28mgetattr\u001B[39m(obj, attr, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m     61\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m cached \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     62\u001B[39m     cached = \u001B[38;5;28mself\u001B[39m.fget(obj)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/MasterProject/Summarization/summrization_webapp/flaskProject2/.venv/lib/python3.12/site-packages/transformers/training_args.py:2103\u001B[39m, in \u001B[36m_setup_devices\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   2096\u001B[39m         warnings.warn(\n\u001B[32m   2097\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33m`--push_to_hub_model_id` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2098\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33m`--hub_model_id` instead and pass the full repo name to this argument (in this case \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2099\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.hub_model_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m).\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   2100\u001B[39m             \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[32m   2101\u001B[39m         )\n\u001B[32m   2102\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.push_to_hub_organization \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2103\u001B[39m     \u001B[38;5;28mself\u001B[39m.hub_model_id = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.push_to_hub_organization\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mPath(\u001B[38;5;28mself\u001B[39m.output_dir).name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m   2104\u001B[39m     warnings.warn(\n\u001B[32m   2105\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m`--push_to_hub_organization` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2106\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m`--hub_model_id` instead and pass the full repo name to this argument (in this case \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2107\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.hub_model_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m).\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   2108\u001B[39m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[32m   2109\u001B[39m     )\n\u001B[32m   2111\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.eval_use_gather_object \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_accelerate_available(\u001B[33m\"\u001B[39m\u001B[33m0.30.0\u001B[39m\u001B[33m\"\u001B[39m):\n",
      "\u001B[31mImportError\u001B[39m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T04:00:28.671954Z",
     "start_time": "2025-01-02T13:43:14.357969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ],
   "id": "5ac1aa74b273f273",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11256' max='11256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11256/11256 14:17:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.275600</td>\n",
       "      <td>3.719555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.035000</td>\n",
       "      <td>3.648158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.894000</td>\n",
       "      <td>3.626880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11256, training_loss=4.154550298868381, metrics={'train_runtime': 51434.1435, 'train_samples_per_second': 0.875, 'train_steps_per_second': 0.219, 'total_flos': 1.1762844696576e+16, 'train_loss': 4.154550298868381, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T16:25:12.259469Z",
     "start_time": "2025-01-06T16:25:12.099283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained(\"./arabic_gpt2_finetuned\")\n",
    "tokenizer.save_pretrained(\"./arabic_gpt2_finetuned\")"
   ],
   "id": "3f7168d6de2f4b0c",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Save the fine-tuned model and tokenizer\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39msave_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./arabic_gpt2_finetuned\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      3\u001B[0m tokenizer\u001B[38;5;241m.\u001B[39msave_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./arabic_gpt2_finetuned\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5bd8afd80bcb8a49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T10:29:19.334682Z",
     "start_time": "2025-01-04T10:29:19.247042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_text = \"Ù‚Ø·Ø±\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", padding=True).to(\"cpu\")\n",
    "\n",
    "# Generate text\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    max_length=200,\n",
    "    num_beams=5,\n",
    "    no_repeat_ngram_size=2,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# Decode the output\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Generated Text:\")\n",
    "print(generated_text)"
   ],
   "id": "2cbbfb03501d1b8c",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m input_text \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mÙ‚Ø·Ø±\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 2\u001B[0m input_ids \u001B[38;5;241m=\u001B[39m \u001B[43mtokenizer\u001B[49m\u001B[38;5;241m.\u001B[39mencode(input_text, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Generate text\u001B[39;00m\n\u001B[1;32m      5\u001B[0m output \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mgenerate(\n\u001B[1;32m      6\u001B[0m     input_ids,\n\u001B[1;32m      7\u001B[0m     max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m200\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     10\u001B[0m     early_stopping\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     11\u001B[0m )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e66f7c52c3b2bb9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b44fbea282c52131"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T06:18:36.487638Z",
     "start_time": "2025-01-03T06:18:36.220555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained(\"./smart_soft_arabic_gpt2\")\n",
    "tokenizer.save_pretrained(\"./smart_soft_arabic_gpt2\")"
   ],
   "id": "79d0427ca73932d4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./smart_soft_arabic_gpt2/tokenizer_config.json',\n",
       " './smart_soft_arabic_gpt2/special_tokens_map.json',\n",
       " './smart_soft_arabic_gpt2/vocab.json',\n",
       " './smart_soft_arabic_gpt2/merges.txt',\n",
       " './smart_soft_arabic_gpt2/added_tokens.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f6c1ac35e1ea8790"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T07:54:47.032427Z",
     "start_time": "2025-03-15T07:54:41.965931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset\n",
    "from arabert.preprocess import ArabertPreprocessor\n"
   ],
   "id": "a52e72bab95653f8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jameelamer/MasterProject/Summarization/summrization_webapp/flaskProject2/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T07:54:56.182245Z",
     "start_time": "2025-03-15T07:54:56.089469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Load GPT-2 model and tokenizer for Arabic\n",
    "model_name = \"./sss-arabic_gpt2_finetuned\"  # Pre-trained Arabic GPT-2\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)"
   ],
   "id": "ff12ce1d5e760553",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T07:55:06.917115Z",
     "start_time": "2025-03-15T07:54:58.118092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_text =\"Ø§Ù„Ø­Ø±Ø¨ Ø§Ù„Ø³ÙˆØ±ÙŠØ©\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", padding=True).to(\"cpu\")\n",
    "\n",
    "# Generate text\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    max_length=200,\n",
    "    num_beams=5,\n",
    "    no_repeat_ngram_size=2,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# Decode the output\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Generated Text:\")\n",
    "print(generated_text)"
   ],
   "id": "e2a842f8e2101855",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:\n",
      "Ø§Ù„Ø­Ø±Ø¨ Ø§Ù„Ø³ÙˆØ±ÙŠØ© Ù…Ø³ØªÙ…Ø±Ø© Ù…Ù†Ø° Ø£ÙƒØ«Ø± Ù…Ù† Ø«Ù„Ø§Ø« Ø³Ù†ÙˆØ§Øª ÙˆÙ‚Ø§Ù„ Ø§Ù„Ù…Ø±ØµØ¯ Ø§Ù„Ø³ÙˆØ±ÙŠ Ù„Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ø¥Ù†Ø³Ø§Ù† Ø§Ù„Ù…Ø¹Ø§Ø±Ø¶ ØŒ ÙˆÙ…Ù‚Ø±Ù‡ Ø¨Ø±ÙŠØ·Ø§Ù†ÙŠØ§ ØŒ Ø¥Ù† Ø§Ù„ØºØ§Ø±Ø§Øª Ø§Ù„Ø¬ÙˆÙŠØ© Ø§Ù„ØªÙŠ ÙŠØ´Ù†Ù‡Ø§ Ø§Ù„ØªØ­Ø§Ù„Ù Ø§Ù„Ø¯ÙˆÙ„ÙŠ Ø¨Ù‚ÙŠØ§Ø¯Ø© Ø§Ù„ÙˆÙ„Ø§ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø© Ø¹Ù„Ù‰ Ù…ÙˆØ§Ù‚Ø¹ ØªÙ†Ø¸ÙŠÙ… \" Ø§Ù„Ø¯ÙˆÙ„Ø© Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ© \" ÙÙŠ Ù…Ø­Ø§ÙØ¸Ø© Ø¯ÙŠØ± Ø§Ù„Ø²ÙˆØ± Ø£Ø³ÙØ±Øª Ø¹Ù† Ù…Ù‚ØªÙ„ Ø§Ù„Ø¹Ø´Ø±Ø§Øª Ù…Ù† Ù…Ø³Ù„Ø­ÙŠ Ø§Ù„ØªÙ†Ø¸ÙŠÙ… . ÙˆØ£Ø¶Ø§Ù Ø§Ù„Ù…Ø±ØµØ¯ Ø£Ù† Ø§Ù„ØºØ§Ø±Ø§Øª Ø£Ø³ÙØ±Øª Ø£ÙŠØ¶Ø§ Ø¹Ù† ØªØ¯Ù…ÙŠØ± Ø¹Ø¯Ø¯ Ù…Ù† Ø§Ù„Ù…Ù†Ø§Ø²Ù„ ÙÙŠ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© . ÙˆÙ‚Ø§Ù„ Ø±Ø§Ù…ÙŠ Ø¹Ø¨Ø¯ Ø§Ù„Ø±Ø­Ù…Ù† Ù…Ø¯ÙŠØ± Ø§Ù„Ù…Ø±ØµØ¯ ØŒ Ø§Ù„Ø°ÙŠ ÙŠØªØ®Ø° Ù…Ù† Ø¨Ø±ÙŠØ·Ø§Ù†ÙŠØ§ Ù…Ù‚Ø±Ø§ Ù„Ù‡ ØŒ Ù„Ø¨ÙŠ Ø¨ÙŠ Ø³ÙŠ Ø¥Ù† Ø§Ù„Ø¶Ø±Ø¨Ø§Øª Ø§Ù„Ø¬ÙˆÙŠØ© Ø§Ø³ØªÙ‡Ø¯ÙØª Ù…ÙˆØ§Ù‚Ø¹ Ù„Ù„ØªÙ†Ø¸ÙŠÙ… ÙÙŠ Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ø¨ÙˆÙƒÙ…Ø§Ù„ ØŒ Ø´Ø±Ù‚ÙŠ Ø³ÙˆØ±ÙŠØ§ . Ù…ÙˆØ§Ø¶ÙŠØ¹ Ù‚Ø¯ ØªÙ‡Ù…Ùƒ Ù†Ù‡Ø§ÙŠØ© ÙˆØ£Ø¶Ø§Ù Ø£Ù† Ø·Ø§Ø¦Ø±Ø§Øª Ø§Ù„ØªØ­Ø§Ù„Ù Ø´Ù†Øª Ø£ÙŠØ¶Ø§ ØºØ§Ø±Ø§Øª Ø¹Ù„Ù‰ Ù…Ù†Ø§Ø·Ù‚ Ø£Ø®Ø±Ù‰ ÙÙŠ Ø³ÙˆØ±ÙŠØ§ ØŒ Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ø±Ù‚Ø© ØŒ Ø§Ù„ØªÙŠ ÙŠØ³ÙŠØ·Ø± Ø¹Ù„ÙŠÙ‡Ø§ Ù…Ø³Ù„Ø­Ùˆ Ø§Ù„ØªÙ†Ø¸ÙŠÙ… ØŒ Ø¨Ø­Ø³Ø¨ Ø§Ù„Ù…Ø±ØµØ¯ . ÙˆØ£Ø´Ø§Ø± Ø§Ù„Ù…Ø±ØµØ¯ Ø¥Ù„Ù‰ Ø£Ù† ØºØ§Ø±Ø§Øª Ø§Ù„ØªØ­Ø§Ù„Ù Ø§Ø³ØªÙ‡Ø¯ÙØª Ø£ÙŠØ¶Ø§ Ù…ÙˆØ§Ù‚Ø¹ Ù„Ù…Ø³Ù„Ø­ÙŠ Ø§Ù„ØªÙ†Ø¸ÙŠÙ… ÙÙŠ Ø§Ù„Ø±Ù‚Ø© ÙˆØ¯ÙŠØ± Ø§Ù„Ø²ÙˆØ± . ÙˆÙƒØ§Ù†Øª Ø§Ù„Ù‚ÙˆØ§Øª Ø§Ù„Ø­ÙƒÙˆÙ…ÙŠØ© Ø§Ù„Ø³ÙˆØ±ÙŠØ© ØŒ Ù…Ø¯Ø¹ÙˆÙ…Ø© Ø¨ØºØ·Ø§Ø¡ Ø¬ÙˆÙŠ Ø±ÙˆØ³ÙŠ ØŒ Ù‚Ø¯ Ø´Ù†Øª ÙÙŠ ÙˆÙ‚Øª Ø³Ø§Ø¨Ù‚ Ù…Ù† Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ø¬Ø§Ø±ÙŠ ØŒ Ø¹Ù…Ù„ÙŠØ© Ø¹Ø³ÙƒØ±ÙŠØ© Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ø³ÙŠØ·Ø±Ø© Ø¹Ù„Ù‰ Ù…Ø¯ÙŠÙ†Ø© ØªØ¯Ù…Ø± Ø§Ù„Ø£Ø«Ø±ÙŠØ© ØŒ Ø§Ù„ÙˆØ§Ù‚Ø¹Ø© Ø¹Ù„Ù‰ Ø¨Ø¹Ø¯ 50 ÙƒÙŠÙ„ÙˆÙ…ØªØ±Ø§ ØºØ±Ø¨ Ø§Ù„Ø¹Ø§ØµÙ…Ø© Ø§Ù„Ø³ÙˆØ±ÙŠØ© Ø¯Ù…Ø´Ù‚ ØŒ ÙˆØ§Ù„ØªÙŠ ØªØ¹Ø¯ Ù…Ù† Ø£Ù‡Ù… Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø£Ø«Ø±ÙŠØ© ÙÙŠ Ø§Ù„Ø¹Ø§Ù„Ù… . ÙˆÙƒØ§Ù† Ø§Ù„ØªÙ†Ø¸ÙŠÙ… Ù‚Ø¯ Ø³ÙŠØ·Ø± Ø¹Ù„Ù‰ ØªØ¯Ù…Ø± ÙÙŠ ÙŠÙˆÙ†ÙŠÙˆ - Ø­Ø²ÙŠØ±Ø§Ù†\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
